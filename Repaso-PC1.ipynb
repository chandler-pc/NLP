{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1ed2c29",
   "metadata": {},
   "source": [
    "### Repaso de ejercicios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223527dc",
   "metadata": {},
   "source": [
    "**Ejercicio 1: Expresiones regulares - Captura de grupos y Lookahead**\n",
    "\n",
    "Implementa una función extract_emails que extraiga correos electrónicos de un texto, validando que los correos sean seguidos por un punto y no por una coma (lookahead positivo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e4e9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_emails(text: str):\n",
    "    # Completa la expresión regular para capturar los correos con lookahead positivo\n",
    "    return re.findall(r\"\", text)\n",
    "\n",
    "# Pruebas\n",
    "assert extract_emails(\"Contacta a example@mail.com. o sales@company.org.\") == [\"example@mail.com\", \"sales@company.org\"]\n",
    "assert extract_emails(\"Envíalo a hr@company.net, por favor.\") == []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa1c62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47220153",
   "metadata": {},
   "source": [
    "**Ejercicio 2 : Tokenización de subpalabras con Byte-Pair Encoding (BPE)**\n",
    "\n",
    "Desarrolla una función bpe_tokenize que utilice el algoritmo BPE para tokenizar una lista de palabras basada en fusiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02226f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpe_tokenize(vocab: dict, num_merges: int):\n",
    "    # Completa el algoritmo BPE para tokenización\n",
    "    pass\n",
    "\n",
    "# Pruebas\n",
    "vocab = {\"l o w e s t\": 5, \"n e w e s t\": 6, \"w i d e s t\": 3}\n",
    "assert bpe_tokenize(vocab, 2) == [\"l o w\", \"n e w e s t\", \"w i d e s t\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b5c66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f465e4",
   "metadata": {},
   "source": [
    "**Ejercicio 3: Lemmatización y Stemming**\n",
    "\n",
    "Crea una función normalize_words que aplique tanto lematización como stemming a una lista de palabras y devuelva los resultados normalizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c470cb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "def normalize_words(words: list):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stemmer = PorterStemmer()\n",
    "    # completa...\n",
    "\n",
    "# Pruebas\n",
    "words = [\"running\", \"jumps\", \"eaten\"]\n",
    "lemmatized, stemmed = normalize_words(words)\n",
    "assert lemmatized == [\"running\", \"jump\", \"eaten\"]\n",
    "assert stemmed == [\"run\", \"jump\", \"eaten\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00f8afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bb6815",
   "metadata": {},
   "source": [
    "**Ejercicio 4: Algoritmo de N-gramas con Máxima Verosimilitud (MLE)**\n",
    "\n",
    "Implementa la clase NgramModelMLE que calcule la probabilidad de una secuencia usando máxima verosimilitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c84744",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NgramModelMLE:\n",
    "    def __init__(self, n: int, corpus: list):\n",
    "        self.n = n\n",
    "        self.corpus = corpus\n",
    "        self.ngram_counts = {}\n",
    "        self._train()\n",
    "\n",
    "    def _train(self):\n",
    "        # Completa el entrenamiento del modelo N-gram\n",
    "        pass\n",
    "\n",
    "    def calculate_probability(self, sequence: list):\n",
    "        # Calcula la probabilidad usando MLE\n",
    "        pass\n",
    "\n",
    "# Pruebas\n",
    "corpus = [\"el gato come pescado\", \"el perro come hueso\"]\n",
    "ngram_model = NgramModelMLE(2, corpus)\n",
    "assert abs(ngram_model.calculate_probability([\"el\", \"gato\"])) - 0.5 < 0.01\n",
    "assert abs(ngram_model.calculate_probability([\"el\", \"perro\"])) - 0.5 < 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f20c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe028bde",
   "metadata": {},
   "source": [
    "**Ejercicio 5: Evaluación de modelos de lenguaje con Perplexity**\n",
    "\n",
    "Desarrolla una función calculate_perplexity que evalúe un modelo n-grama calculando la perplexity para un conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436eb331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(ngram_model, test_data: list):\n",
    "    perplexity = 0\n",
    "    total_words = 0\n",
    "    # completa...\n",
    "\n",
    "# Pruebas\n",
    "test_data = [\"el gato come pescado\", \"el perro ladra fuerte\"]\n",
    "ngram_model = NgramModelMLE(2, test_data)\n",
    "assert calculate_perplexity(ngram_model, test_data) < 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b88b21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dfab9e",
   "metadata": {},
   "source": [
    "**Ejercicio 6: Sampling de frases desde un modelo de lenguaje**\n",
    "\n",
    "Implementa una función generate_sentence que genere frases desde un modelo n-grama mediante sampling probabilístico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fd496f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_sentence(ngram_model, max_length: int):\n",
    "    sentence = []\n",
    "    word = \"<START>\"\n",
    "\n",
    "    while word != \"<END>\" and len(sentence) < max_length:\n",
    "        ...\n",
    "\n",
    "    return \" \".join(sentence)\n",
    "\n",
    "# Pruebas\n",
    "corpus = [\"el gato come pescado\", \"el perro come hueso\"]\n",
    "ngram_model = NgramModelMLE(2, corpus)\n",
    "generated_sentence = generate_sentence(ngram_model, 10)\n",
    "assert len(generated_sentence.split()) <= 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e35fc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5329dbf7",
   "metadata": {},
   "source": [
    "**Ejercicio 7:  Suavizado Kneser-Ney**\n",
    "    \n",
    "Implementa la clase KneserNeyModel que utilice suavizado Kneser-Ney para el cálculo de probabilidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8e61f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KneserNeyModel:\n",
    "    def __init__(self, n: int, corpus: list, discount: float):\n",
    "        self.n = n\n",
    "        self.corpus = corpus\n",
    "        self.discount = discount\n",
    "        self.ngram_counts = {}\n",
    "        self.continuation_counts = {}\n",
    "        self._train()\n",
    "\n",
    "    def _train(self):\n",
    "        # Completa el entrenamiento del modelo con suavizado Kneser-Ney\n",
    "        pass\n",
    "\n",
    "    def calculate_probability(self, sequence: list):\n",
    "        # Implementa el cálculo de probabilidad con Kneser-Ney\n",
    "        pass\n",
    "\n",
    "# Pruebas\n",
    "corpus = [\"el gato come pescado\", \"el perro come hueso\"]\n",
    "kneser_ney_model = KneserNeyModel(2, corpus, 0.75)\n",
    "assert abs(kneser_ney_model.calculate_probability([\"el\", \"gato\"])) - 0.5 < 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae40f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf178f5",
   "metadata": {},
   "source": [
    "**Ejercicio 8: Tokenización basada en reglas**\n",
    "\n",
    "Desarrolla una función rule_based_tokenization que divida un texto en oraciones, y luego en palabras, basándose en signos de puntuación y espacios. Asegúrate de mantener los signos de puntuación como tokens separados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4911e96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule_based_tokenization(text: str):\n",
    "    # Completa la función de tokenización basada en reglas\n",
    "    pass\n",
    "\n",
    "# Pruebas\n",
    "assert rule_based_tokenization(\"Hola. ¿Cómo estás? Bien.\") == [[\"Hola\", \".\"], [\"¿\", \"Cómo\", \"estás\", \"?\"], [\"Bien\", \".\"]]\n",
    "assert rule_based_tokenization(\"¡Hola, mundo!\") == [[\"¡\", \"Hola\", \",\", \"mundo\", \"!\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a587e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e197f2",
   "metadata": {},
   "source": [
    "**Ejercicio 9: Algoritmo WordPiece de tokenización**\n",
    "\n",
    "Implementa una función wordpiece_tokenize que tome un vocabulario y una oración, y realice la tokenización usando el algoritmo WordPiece. El vocabulario está predefinido y cada palabra debe dividirse en subpalabras cuando no esté en el vocabulario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb80552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordpiece_tokenize(vocab: set, sentence: str):\n",
    "    # Completa la función de tokenización WordPiece\n",
    "    pass\n",
    "\n",
    "# Pruebas\n",
    "vocab = {\"el\", \"gato\", \"per\", \"##ro\", \"come\", \"##mos\", \"##do\"}\n",
    "assert wordpiece_tokenize(vocab, \"el perro come comida\") == [\"el\", \"per\", \"##ro\", \"come\", \"com\", \"##ida\"]\n",
    "assert wordpiece_tokenize(vocab, \"el gato come\") == [\"el\", \"gato\", \"come\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1ae4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03efa2ef",
   "metadata": {},
   "source": [
    "**Ejercicio 10: Modelo de Lenguaje N-Grama con Backoff**\n",
    "\n",
    "Implementa una clase NgramModelWithBackoff que implemente backoff para calcular la probabilidad de secuencias que no se encuentran en el modelo de n-gramas, usando modelos más pequeños (por ejemplo, de bigramas a unigrams)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a882e1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {'el': 2, 'gato': 1, 'come': 2, 'pescado': 1, 'perro': 1, 'hueso': 1}, 2: {'el gato': 1, 'gato come': 1, 'come pescado': 1, 'el perro': 1, 'perro come': 1, 'come hueso': 1}}\n",
      "0.5\n",
      "0.5\n",
      "0.125\n"
     ]
    }
   ],
   "source": [
    "class NgramModelWithBackoff:\n",
    "    def __init__(self, n: int, corpus: list):\n",
    "        self.n = n\n",
    "        self.corpus = corpus\n",
    "        self.ngram_counts = {}\n",
    "        for i in range(1,n+1):\n",
    "            self.ngram_counts[i] = {}\n",
    "        self._train()\n",
    "\n",
    "    def _train(self):\n",
    "        for sentence in corpus:\n",
    "            sentence = sentence.split(\" \")\n",
    "            for i in range(1,self.n+1):\n",
    "                for j in range(len(sentence)-(i-1)):\n",
    "                    ngram = \" \".join([word for word in [sentence[k] for k in range(j,j+i)]])\n",
    "                    self.add_to_ngram(i,ngram)\n",
    "        print(self.ngram_counts)\n",
    "\n",
    "    def add_to_ngram(self, n: int, words: str):\n",
    "        if words not in self.ngram_counts[n]:\n",
    "            self.ngram_counts[n][words] = 1\n",
    "        else:\n",
    "            self.ngram_counts[n][words] += 1\n",
    "\n",
    "    def calculate_probability(self, sequence: list):\n",
    "        return self._backoff(self.n, sequence)\n",
    "    \n",
    "    \n",
    "    def _backoff(self, n: int, sequence: list):\n",
    "        if n == 1:\n",
    "            return self.ngram_counts[1].get(sequence[0], 0) / sum(self.ngram_counts[1].values())\n",
    "        count = self.ngram_counts[n].get(\" \".join(sequence), 0)\n",
    "        if count > 0:\n",
    "            return count / self.ngram_counts[n-1].get(\" \".join(sequence[:-1]), 1)\n",
    "        else:\n",
    "            return self._backoff(n-1, sequence[1:])\n",
    "        \n",
    "\n",
    "# Pruebas\n",
    "corpus = [\"el gato come pescado\", \"el perro come hueso\"]\n",
    "ngram_model_backoff = NgramModelWithBackoff(2, corpus)\n",
    "assert abs(ngram_model_backoff.calculate_probability([\"el\", \"gato\"])) - 0.5 < 0.1\n",
    "assert abs(ngram_model_backoff.calculate_probability([\"come\", \"hueso\"])) - 0.5 < 0.1\n",
    "print(ngram_model_backoff.calculate_probability([\"el\",\"gato\"]))\n",
    "print(ngram_model_backoff.calculate_probability([\"come\",\"hueso\"]))\n",
    "print(ngram_model_backoff.calculate_probability([\"perro\",\"pescado\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0b72f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970cd8d1",
   "metadata": {},
   "source": [
    "**Ejercicio 11: Perplexity como promedio ponderado del factor de ramificación**\n",
    "\n",
    "Extiende la función calculate_perplexity_weighted para incluir el cálculo del factor de ramificación ponderado y así evaluar el desempeño del modelo de lenguaje n-gram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1857a8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity_weighted(ngram_model, test_data: list):\n",
    "    total_log_prob = 0\n",
    "    total_words = 0\n",
    "    branching_factors = []\n",
    "\n",
    "    for sentence in test_data:\n",
    "        words = sentence.split()\n",
    "        log_prob = ngram_model.calculate_probability(words)\n",
    "        branching_factor = len(words) ** (1 / len(words))\n",
    "        total_log_prob += log_prob\n",
    "        branching_factors.append(branching_factor)\n",
    "        total_words += len(words)\n",
    "\n",
    "    weighted_branching = sum(branching_factors) / len(branching_factors)\n",
    "    return 2 ** (-total_log_prob / (total_words * weighted_branching))\n",
    "\n",
    "# Pruebas\n",
    "test_data = [\"el gato come pescado\", \"el perro ladra fuerte\"]\n",
    "ngram_model = NgramModelWithBackoff(2, test_data)\n",
    "assert calculate_perplexity_weighted(ngram_model, test_data) < 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d216cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b82656e",
   "metadata": {},
   "source": [
    "**Ejercicio 12: Interpolación y Backoff en modelos de lenguaje**\n",
    "\n",
    "Implementa una función interpolated_ngram_model que combine modelos unigramas, bigramas y trigramas usando interpolación y backoff para calcular las probabilidades de secuencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e47986b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InterpolatedNgramModel:\n",
    "    def __init__(self, corpus: list):\n",
    "        self.unigram_counts = {}\n",
    "        self.bigram_counts = {}\n",
    "        self.trigram_counts = {}\n",
    "        self.total_unigrams = 0\n",
    "        self._train(corpus)\n",
    "\n",
    "    def _train(self, corpus):\n",
    "        # Completa el entrenamiento con interpolación de unigramas, bigramas y trigramas\n",
    "        pass\n",
    "\n",
    "    def calculate_probability(self, sequence: list):\n",
    "        # Implementa el cálculo de probabilidad usando interpolación y backoff\n",
    "        pass\n",
    "\n",
    "# Pruebas\n",
    "corpus = [\"el gato come pescado\", \"el perro come hueso\"]\n",
    "interpolated_model = InterpolatedNgramModel(corpus)\n",
    "assert abs(interpolated_model.calculate_probability([\"el\", \"gato\", \"come\"])) - 0.5 < 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aada9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ab9606",
   "metadata": {},
   "source": [
    "**Ejercicio 13: Evaluación de modelos de lenguaje - Suavizado Kneser-Ney vs. MLE**\n",
    "\n",
    "Implementa una función evaluate_language_models que compare los modelos de suavizado Kneser-Ney y MLE utilizando perplexity para un conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4340e019",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_language_models(mle_model, kn_model, test_data: list):\n",
    "    mle_perplexity = calculate_perplexity(mle_model, test_data)\n",
    "    kn_perplexity = calculate_perplexity(kn_model, test_data)\n",
    "    # completa el codigo\n",
    "    \n",
    "    return {\"MLE\": mle_perplexity, \"Kneser-Ney\": kn_perplexity}\n",
    "\n",
    "# Pruebas\n",
    "corpus = [\"el gato come pescado\", \"el perro come hueso\"]\n",
    "test_data = [\"el gato come\", \"el perro ladra\"]\n",
    "mle_model = NgramModelMLE(2, corpus)\n",
    "kn_model = KneserNeyModel(2, corpus, 0.75)\n",
    "results = evaluate_language_models(mle_model, kn_model, test_data)\n",
    "assert results[\"MLE\"] > results[\"Kneser-Ney\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f063c31",
   "metadata": {},
   "source": [
    "**Ejercicio 14: Expresiones regulares con grupos y sustitución**\n",
    "\n",
    "Implementa una función normalize_text que realice las siguientes operaciones en un texto dado:\n",
    "\n",
    "- Remplaza todos los dígitos por el token \"<NUM>\".\n",
    "- Convierte todas las secuencias de espacios múltiples en un solo espacio.\n",
    "- Reemplaza los pronombres personales \"yo\", \"tú\", \"él\" por \"PRON\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002a9ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize_text(text: str):\n",
    "    # Completa la función usando expresiones regulares\n",
    "    pass\n",
    "\n",
    "# Pruebas\n",
    "assert normalize_text(\"Yo tengo 2 perros y  3 gatos\") == \"PRON tengo <NUM> perros y <NUM> gatos\"\n",
    "assert normalize_text(\"Él y  tú  están aquí\") == \"PRON y PRON están aquí\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c94906",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecf4963",
   "metadata": {},
   "source": [
    "**Ejercicio 15: Algoritmo BPE con capturas y tokenización por subpalabras**\n",
    "\n",
    "Implementa una función bpe_tokenize_v2 que use el algoritmo BPE para dividir palabras en subpalabras y capture las fusiones más frecuentes. La función debe devolver las fusiones en orden descendente de frecuencia.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e7b120",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpe_tokenize_v2(vocab: dict, num_merges: int):\n",
    "    # Implementa el algoritmo BPE con fusiones capturadas\n",
    "    pass\n",
    "\n",
    "# Pruebas\n",
    "vocab = {\"l o w e s t\": 5, \"n e w e s t\": 6, \"w i d e s t\": 3}\n",
    "assert bpe_tokenize_v2(vocab, 3) == [(\"e s\", 11), (\"w e\", 9), (\"s t\", 8)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcf7311",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b1440f",
   "metadata": {},
   "source": [
    "**Ejercicio 16: Levenshtein y la distancia mínima de edición con operaciones**\n",
    "\n",
    "Implementa una función levenshtein_operations que, además de calcular la distancia de Levenshtein, devuelva las operaciones necesarias (inserciones, borrados, sustituciones) para transformar una palabra en otra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d17a8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein_operations(word1: str, word2: str):\n",
    "    # Implementa el algoritmo que calcule las operaciones de edición\n",
    "    pass\n",
    "\n",
    "# Pruebas\n",
    "assert levenshtein_operations(\"kitten\", \"sitting\") == (3, [(\"replace\", \"k\", \"s\"), (\"insert\", \"t\"), (\"insert\", \"g\")])\n",
    "assert levenshtein_operations(\"flaw\", \"lawn\") == (2, [(\"delete\", \"f\"), (\"replace\", \"w\", \"n\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d3a0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffa6d34",
   "metadata": {},
   "source": [
    "**Ejercicio 17:Tokenización top-down basada en reglas**\n",
    "\n",
    "Crea una función rule_based_tokenization que divida un texto en oraciones y palabras siguiendo las reglas gramaticales del español, por ejemplo:\n",
    "\n",
    "- Las oraciones terminan en puntos.\n",
    "- Las comas y los signos de exclamación o interrogación deben mantenerse como tokens separados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d2ce32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule_based_tokenization(text: str):\n",
    "    # Implementa la tokenización basada en reglas\n",
    "    pass\n",
    "\n",
    "# Pruebas\n",
    "assert rule_based_tokenization(\"¿Cómo estás? Bien, gracias.\") == [[\"¿\", \"Cómo\", \"estás\", \"?\"], [\"Bien\", \",\", \"gracias\", \".\"]]\n",
    "assert rule_based_tokenization(\"Hola. ¿Qué tal?\") == [[\"Hola\", \".\"], [\"¿\", \"Qué\", \"tal\", \"?\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c973541",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a959b928",
   "metadata": {},
   "source": [
    "**Ejercicio 18: Modelado de lenguaje con interpolación y backoff**\n",
    "\n",
    "Implementa una función interpolated_ngram_model que combine modelos de unigramas, bigramas y trigramas usando interpolación y backoff. Debe asignar probabilidades más altas a los n-gramas más largos y, si no se encuentra un n-grama, hacer \"backoff\" al siguiente modelo más pequeño.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff939d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InterpolatedNgramModel:\n",
    "    def __init__(self, corpus: list):\n",
    "        self.unigram_model = {}\n",
    "        self.bigram_model = {}\n",
    "        self.trigram_model = {}\n",
    "        # Inicializa los modelos\n",
    "        \n",
    "    def calculate_interpolated_probability(self, sequence: list):\n",
    "        # Completa el cálculo de probabilidades con interpolación y backoff\n",
    "        pass\n",
    "\n",
    "# Pruebas\n",
    "corpus = [\"el gato come pescado\", \"el perro come hueso\"]\n",
    "interpolated_model = InterpolatedNgramModel(corpus)\n",
    "assert abs(interpolated_model.calculate_interpolated_probability([\"el\", \"gato\", \"come\"])) - 0.6 < 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f88a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc7096e",
   "metadata": {},
   "source": [
    "**Ejercicio 19: Estimación de probabilidades con MLE y suavizado de Laplace**\n",
    "\n",
    "Desarrolla una función ngram_probability_with_smoothing que calcule las probabilidades de un modelo n-grama usando MLE y suavizado de Laplace.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4141f4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_probability_with_smoothing(n: int, corpus: list, sequence: list):\n",
    "    # Implementa el cálculo con MLE y suavizado de Laplace\n",
    "    pass\n",
    "\n",
    "# Pruebas\n",
    "corpus = [\"el gato come\", \"el perro ladra\"]\n",
    "assert abs(ngram_probability_with_smoothing(2, corpus, [\"el\", \"gato\"])) - 0.5 < 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36aac85",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f990094",
   "metadata": {},
   "source": [
    "**Referencias de corpus:**\n",
    "    \n",
    "- Brown Corpus: Un corpus general de inglés.\n",
    "- Gutenberg Corpus: Libros de dominio público para entrenamiento de modelos de lenguaje.\n",
    "- Europarl Corpus: Transcripciones de sesiones parlamentarias multilingües."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f703b3",
   "metadata": {},
   "source": [
    "**Ejercicio 20: Modelo de lenguaje n-Grama regularizado con Dropout**\n",
    "\n",
    "Implementa una clase NgramModelWithDropout que entrene un modelo de lenguaje n-grama con regularización mediante Dropout. La probabilidad de \"eliminar\" un n-grama debe ser un hiperparámetro ajustable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275b71dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class NgramModelWithDropout:\n",
    "    def __init__(self, n: int, corpus: list, dropout_rate: float):\n",
    "        self.n = n\n",
    "        self.corpus = corpus\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.ngram_counts = {}\n",
    "        self._train()\n",
    "\n",
    "    def _train(self):\n",
    "        # Completa la función para entrenar el modelo con Dropout en los n-gramas\n",
    "        pass\n",
    "\n",
    "    def calculate_probability(self, sequence: list):\n",
    "        # Implementa el cálculo de probabilidad usando el modelo con Dropout\n",
    "        pass\n",
    "\n",
    "# Pruebas\n",
    "corpus = [\"el gato come pescado\", \"el perro come hueso\", \"el gato salta\"]\n",
    "ngram_dropout = NgramModelWithDropout(2, corpus, 0.2)\n",
    "assert abs(ngram_dropout.calculate_probability([\"el\", \"gato\"])) - 0.5 < 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd127e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5424269",
   "metadata": {},
   "source": [
    "**Ejercicio 21: Entrenamiento de un modelo de n-gramas usando smoothing interpolado y backoff con ajuste de hiperparámetros**\n",
    "\n",
    "Crea una clase AdvancedNgramModel que implemente interpolación y backoff, y que permita ajustar los hiperparámetros de interpolación usando búsqueda en cuadrícula (Grid Search). El objetivo es minimizar el perplexity del modelo en un conjunto de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85860b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "class AdvancedNgramModel:\n",
    "    def __init__(self, n: int, corpus: list):\n",
    "        self.n = n\n",
    "        self.corpus = corpus\n",
    "        self.ngram_probs = {}\n",
    "        self._train()\n",
    "\n",
    "    def _train(self):\n",
    "        # Completa el entrenamiento con interpolación y backoff\n",
    "        pass\n",
    "\n",
    "    def calculate_perplexity(self, sequence: list):\n",
    "        # Calcula la perplexity de una secuencia\n",
    "        pass\n",
    "\n",
    "    def tune_hyperparameters(self, param_grid: dict):\n",
    "        # Implementa la búsqueda en cuadrícula para ajuste de hiperparámetros\n",
    "        pass\n",
    "\n",
    "# Pruebas\n",
    "corpus = [\"el gato come pescado\", \"el perro come hueso\", \"el gato salta alto\"]\n",
    "advanced_ngram = AdvancedNgramModel(3, corpus)\n",
    "assert abs(advanced_ngram.calculate_perplexity([\"el\", \"gato\", \"come\"])) - 10 < 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8043b7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e676d498",
   "metadata": {},
   "source": [
    "**Ejercicio 22: Tokenización basada en WordPiece con ajuste dinámico de vocabulario**\n",
    "\n",
    "Implementa una función wordpiece_tokenize_dynamic que ajuste dinámicamente el tamaño del vocabulario según las palabras que se encuentren en el texto. Debe usar WordPiece y asignar más tokens a las palabras raras, y menos tokens a las comunes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836069f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordpiece_tokenize_dynamic(text: str, vocab_size: int):\n",
    "    # Completa la tokenización adaptativa usando WordPiece\n",
    "    pass\n",
    "\n",
    "# Pruebas\n",
    "text = \"el perro corre rápido y el gato también\"\n",
    "tokens = wordpiece_tokenize_dynamic(text, 10)\n",
    "assert len(tokens) <= 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3993ef7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
